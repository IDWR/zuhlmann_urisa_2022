{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "# Note that pandas = pd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD SHAPEFILES to map\n",
    "# Add these shapefiles and data contained in repository to a new map\n",
    "# 1) FH_Perimeter\n",
    "# 2) Roads\n",
    "# 3) Contours non-clipped\n",
    "# 4) original tif (NOTE - only for in-person tutorial)\n",
    "# 5) clipped tiff (NOTE - only for in-person tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATA_LOCATION</th>\n",
       "      <th>MOVE_LOCATION</th>\n",
       "      <th>MOVE_LOCATION_DSET</th>\n",
       "      <th>RENAME</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>DATE_CREATED</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>DATA_LOCATION_ORIGINAL</th>\n",
       "      <th>DATE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ITEM</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>four_corners_fire_perim</th>\n",
       "      <td>NaN</td>\n",
       "      <td>urisa_presentation_gdb</td>\n",
       "      <td>agency</td>\n",
       "      <td>NaN</td>\n",
       "      <td>National Interagency Fire Center</td>\n",
       "      <td>20221002.0</td>\n",
       "      <td>Four Corner Fire boundary selection from NIFC ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoadCore_FS</th>\n",
       "      <td>C:\\Users\\uhlmann\\Documents\\urisa_conference_20...</td>\n",
       "      <td>urisa_presentation_gdb</td>\n",
       "      <td>agency</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             DATA_LOCATION  ... DATE\n",
       "ITEM                                                                        ...     \n",
       "four_corners_fire_perim                                                NaN  ...  NaN\n",
       "RoadCore_FS              C:\\Users\\uhlmann\\Documents\\urisa_conference_20...  ...  NaN\n",
       "\n",
       "[2 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Load df\n",
    "# REPLACE below path/to/data/inventory.csv to location in your directory\n",
    "fp_csv = r'C:\\Users\\uhlmann\\Documents\\urisa_conference_2022\\pandas_jupyter_urisa_2022\\urisa_data_inventory.csv'\n",
    "# read csv into Pandas dataframe\n",
    "df = pd.read_csv(fp_csv, index_col = 'ITEM')\n",
    "# Print df to output - compare to csv and notice it's the verbatim.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'path\\\\to\\\\your\\\\unzipped\\\\git\\\\folder\\\\RoadCore_FS.shp']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Replace base directory in DATA_LOCATION field from csv to your own - currenty it's my base directory\n",
    "# IMPORTANT! change user_git_dir = 'path\\to\\your\\git\\folder'\n",
    "# NOTE - you could also skip this cell and simply replace DATA_LOCATION for RoadCore_FS \n",
    "# to the full/path/to/RoadCore_FS/in/git/dir and rerun cell 1) to reload the dataframe (df)\n",
    "zu_git_dir = r'C:\\Users\\uhlmann\\Documents\\urisa_conference_2022\\pandas_jupyter_urisa_2022\\github_data'\n",
    "user_git_dir = r'path\\to\\your\\unzipped\\git\\folder'\n",
    "\n",
    "# replace paths in dataframe\n",
    "indices = copy.copy(df.index)\n",
    "fp_orig = df.loc[indices, 'DATA_LOCATION']\n",
    "fp_fixed = []\n",
    "for fp in fp_orig:\n",
    "    try:\n",
    "        fp_fixed.append(fp.replace(zu_git_dir, user_git_dir))\n",
    "    # four_corners_fire_perim has no DATA_LOCATION; except clause will handle\n",
    "    except AttributeError:\n",
    "        fp_fixed.append('')\n",
    "df['DATA_LOCATION'] = fp_fixed\n",
    "fp_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_git_dir = zu_git_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'urisa_presentation_gdb': 'C:\\\\Users\\\\uhlmann\\\\Documents\\\\urisa_conference_2022\\\\data_maps\\\\urisa_presentation\\\\urisa_presentation.gdb'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Dictionary for code readability later\n",
    "# REPLACE path/to/gdb.gdb with path/to/gdb.gdb on your directory/computer:\n",
    "# key:val = 'urisa_presentation_gdb': 'path/to/gdb'\n",
    "fp_gdb = os.path.join(user_git_dir, 'urisa_presentation/urisa_presentation.gdb')\n",
    "path_dict = {'urisa_presentation_gdb':fp_gdb}\n",
    "# Print dictionary for inspection\n",
    "path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Variables for copy fc\n",
    "# copy feature from TOC (table of contents)\n",
    "# NOTE: select 4 corners fire from att table!\n",
    "feat_in = 'FH_Perimeter'\n",
    "index = 'four_corners_fire_perim'\n",
    "gdb_target_str = df.loc[index, 'MOVE_LOCATION']\n",
    "# use key: gdb_target_str to get path/to/gdb value from dictionary\n",
    "gdb_target = path_dict[gdb_target_str]\n",
    "dset_name = df.loc[index, 'MOVE_LOCATION_DSET']\n",
    "dir_target = os.path.join(gdb_target, dset_name)\n",
    "dir_target\n",
    "fname = copy.copy(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) CREATE DATASETs - agency, analysis\n",
    "# Open and enter Notebook titled \"basics\" and create datasets by running both cells\n",
    "# Follow instructions therein as we will create TWO datasets: Agency and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC TO COPY:  FH_Perimeter\n",
      "COPY LOCATION:  C:\\Users\\uhlmann\\Documents\\urisa_conference_2022\\data_maps\\urisa_presentation\\urisa_presentation.gdb\\agency\n",
      "FEATURE CLASS NAME OUT:  four_corners_fire_perim\n"
     ]
    }
   ],
   "source": [
    "# 5)Create new FC with JUST Four Corners fire and add to project gdb\n",
    "# IMPORT: select 4 corners fire from attribute table!!\n",
    "\n",
    "print('FC TO COPY: ', feat_in)\n",
    "print('COPY LOCATION: ', dir_target)\n",
    "print('FEATURE CLASS NAME OUT: ', fname)\n",
    "\n",
    "# # # b) Once arguments are confirmed, uncomment and run\n",
    "# arcpy.FeatureClassToFeatureClass_conversion(feat_in, dir_target, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Set values to DataFrame\n",
    "# since we copied the fc to our project gdb, let's add the updated path to dataframe\n",
    "df.loc[index, 'DATA_LOCATION'] = os.path.join(dir_target, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Variables for copy fc\n",
    "# copy features from file path in DataFrame to pro project gdb\n",
    "index = 'RoadCore_FS'\n",
    "feat_in = df.loc[index,'DATA_LOCATION']\n",
    "gdb_target_str = df.loc[index, 'MOVE_LOCATION']\n",
    "gdb_target = path_dict[gdb_target_str]\n",
    "dset_name = df.loc[index, 'MOVE_LOCATION_DSET']\n",
    "dir_target = os.path.join(gdb_target, dset_name)\n",
    "dir_target\n",
    "fname = copy.copy(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC TO COPY:  C:\\Users\\uhlmann\\Documents\\urisa_conference_2022\\data_maps\\data\\shp\\RoadCore_FS.shp\n",
      "COPY LOCATION:  C:\\Users\\uhlmann\\Documents\\urisa_conference_2022\\data_maps\\urisa_presentation\\urisa_presentation.gdb\\agency\n",
      "FEATURE CLASS NAME OUT:  RoadCore_FS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, October 4, 2022 11:16:13 AM\",\"Succeeded at Tuesday, October 4, 2022 11:16:15 AM (Elapsed Time: 1.26 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\uhlmann\\\\Documents\\\\urisa_conference_2022\\\\data_maps\\\\urisa_presentation\\\\urisa_presentation.gdb\\\\agency\\\\RoadCore_FS'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8) Copy roads feature class to Pro gdb\n",
    "print('FC TO COPY: ', feat_in)\n",
    "print('COPY LOCATION: ', dir_target)\n",
    "print('FEATURE CLASS NAME OUT: ', fname)\n",
    "\n",
    "# # b) Once arguments are confirmed, uncomment and run\n",
    "arcpy.FeatureClassToFeatureClass_conversion(feat_in, dir_target, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Set values to DataFrame\n",
    "# save data location original to dataframe\n",
    "df.loc[index,'DATA_LOCATION_ORIGINAL'] = df.loc[index, 'DATA_LOCATION']\n",
    "# since we copied the fc to our project gdb, let's add the updated path to dataframe\n",
    "df.loc[index,'DATA_LOCATION'] = os.path.join(dir_target,fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal presentation ntoes\n",
    "# a) add contours to TOC\n",
    "# b) create new dset - analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE PATH OUT:  C:\\Users\\uhlmann\\Documents\\urisa_conference_2022\\data_maps\\urisa_presentation\\urisa_presentation.gdb\\analysis\\contours_100m_4corners_clipped\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, October 4, 2022 11:18:30 AM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Tuesday, October 4, 2022 11:18:32 AM (Elapsed Time: 2.12 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\uhlmann\\\\Documents\\\\urisa_conference_2022\\\\data_maps\\\\urisa_presentation\\\\urisa_presentation.gdb\\\\analysis\\\\contours_100m_4corners_clipped'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10) Clip contour polygons to fire boundary\n",
    "fp_in = 'contours_100m_4corners'\n",
    "fp_clip = 'four_corners_fire_perim'\n",
    "index = 'contours_100m_4corners_clipped'\n",
    "fname = copy.copy(index)\n",
    "fp_out = os.path.join(gdb, 'analysis', fname)\n",
    "print('FILE PATH OUT: ', fp_out)\n",
    "\n",
    "# # b) Once arguments are confirmed, uncomment and run\n",
    "arcpy.Clip_analysis(fp_in, fp_clip, fp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11) Set values to DataFrame\n",
    "df.loc[index,'DATA_LOCATION'] = fp_out\n",
    "\n",
    "# ADD DATA INFO\n",
    "df.loc[index, 'DATE'] = '20221004'\n",
    "df.loc[index, 'SOURCE'] = 'McMillen Jacobs'\n",
    "df.loc[index, 'ABSTRACT'] = 'Contours derived from the USGS National Elevation Dataset 1/3 arc' \\\n",
    "                            ' second n45w117 20220309.  DEM was smoothed with a gaussian filter' \\\n",
    "                            'prior to generating contours.  Contours at 100m elevation band interval.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Contours derived from the USGS National Elevation Dataset 1/3 arc second n45w117 20220309.  DEM was smoothed with a gaussian filterprior to generating contours.  Contours at 100m elevation band interval.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 12) Inspect dataframe prior to saving.\n",
    "df\n",
    "df.loc[index, 'ABSTRACT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13) Save CSV --> a) Close CSV!!\n",
    "# make sure to close csv first or else Permission Error\n",
    "fp_csv\n",
    "df.to_csv(fp_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
